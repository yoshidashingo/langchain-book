{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzrWQTLn70Ra"
      },
      "source": [
        "# ChatGPTをAPIから利用するために"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKSpjd8v8A9H"
      },
      "source": [
        "## 3-3 入出力の長さの制限や課金に影響する「トークン」"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6fSq7bc8DES"
      },
      "source": [
        "### Tokenizerとtiktokenの紹介"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MPred-0se6z"
      },
      "outputs": [],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWdpn2pw8NGp"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "text = \"LLMを使ってクールなものを作るのは簡単だが、プロダクションで使えるものを作るのは非常に難しい。\"\n",
        "\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "tokens = encoding.encode(text)\n",
        "print(len(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNeWKD2O8JB5"
      },
      "source": [
        "### 日本語のトークン数について"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwIhYtWcshOY"
      },
      "outputs": [],
      "source": [
        "text = \"It’s easy to make something cool with LLMs, but very hard to make something production-ready with them.\"\n",
        "\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "tokens = encoding.encode(text)\n",
        "print(len(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P56iAwzT8Xmq"
      },
      "source": [
        "## 3-4 Chat Completions APIにふれる環境準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIZY8RE38cUC"
      },
      "source": [
        "### Google Colabのノートブック作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4TeCLj3Qe5r"
      },
      "outputs": [],
      "source": [
        "print(\"Hello World\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjYCIb2Q8fbe"
      },
      "source": [
        "### OpenAIのAPIキーの準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4oSu5DqWgpG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0l8ptIe8iH5"
      },
      "source": [
        "## 3-5 Chat Completions APIをさわってみる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p9pLImp8kQ9"
      },
      "source": [
        "### OpenAIのライブラリ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_R8jT7MNRC9t"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTD-Xe9G8r6w"
      },
      "source": [
        "### Chat Completions APIの呼び出し"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHJUSC61Wg_y"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hello! I'm John.\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2THywRt8t0F"
      },
      "source": [
        "### 会話履歴を踏まえた応答を得る"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yk5Cc6rtWtub"
      },
      "outputs": [],
      "source": [
        "openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Hello! I'm John.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Hello John! How can I assist you today?\"},\n",
        "        {\"role\": \"user\", \"content\": \"Do you know my name?\"}\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKRqvj0u8xWL"
      },
      "source": [
        "### ストリーミングで応答を得る"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7J2Gq9PYPBA"
      },
      "outputs": [],
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Hello! I'm John.\"}\n",
        "  ],\n",
        "  stream=True\n",
        ")\n",
        "\n",
        "for chunk in response:\n",
        "  choice = chunk[\"choices\"][0]\n",
        "  if choice[\"finish_reason\"] is None:\n",
        "    print(choice[\"delta\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqKaUhJ08zQ1"
      },
      "source": [
        "### （コラム）Completions API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fD6Z-BZsCF3P"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=\"Hello! I'm John.\"\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKiq30SODvUP"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Human: Hello! I'm John.\n",
        "AI: Nice to meet you, John!\n",
        "Human: Do you know my name?\n",
        "AI: \"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=prompt\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrlT300r83MS"
      },
      "source": [
        "## 3-6 Function calling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwG5cpzg85Vn"
      },
      "source": [
        "### Function callingのサンプルコード\n",
        "\n",
        "[OpenAI の公式ドキュメント](https://platform.openai.com/docs/guides/gpt/function-calling) をもとに一部改変したコードです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K97Pbcw3bly8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def get_current_weather(location, unit=\"celsius\"):\n",
        "    weather_info = {\n",
        "        \"location\": location,\n",
        "        \"temperature\": \"25\",\n",
        "        \"unit\": \"celsius\",\n",
        "        \"forecast\": [\"sunny\", \"windy\"],\n",
        "    }\n",
        "    return json.dumps(weather_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgIGMKtBgeGj"
      },
      "outputs": [],
      "source": [
        "functions = [\n",
        "    {\n",
        "        \"name\": \"get_current_weather\",\n",
        "        \"description\": \"Get the current weather in a given location\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"location\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The city and state, e.g. Tokyo\",\n",
        "                },\n",
        "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "            },\n",
        "            \"required\": [\"location\"],\n",
        "        },\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO-VYo7tghih"
      },
      "outputs": [],
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Tokyo?\"}]\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo-0613\",\n",
        "    messages=messages,\n",
        "    functions=functions\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7LcVydmhlp0"
      },
      "outputs": [],
      "source": [
        "response_message = response[\"choices\"][0][\"message\"]\n",
        "\n",
        "available_functions = {\n",
        "    \"get_current_weather\": get_current_weather,\n",
        "}\n",
        "function_name = response_message[\"function_call\"][\"name\"]\n",
        "fuction_to_call = available_functions[function_name]\n",
        "function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
        "\n",
        "function_response = fuction_to_call(\n",
        "    location=function_args.get(\"location\"),\n",
        "    unit=function_args.get(\"unit\"),\n",
        ")\n",
        "\n",
        "print(function_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xe80yJNwjEJy"
      },
      "outputs": [],
      "source": [
        "messages.append(response_message)\n",
        "messages.append(\n",
        "    {\n",
        "        \"role\": \"function\",\n",
        "        \"name\": function_name,\n",
        "        \"content\": function_response,\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9QBhpRtgtSW"
      },
      "outputs": [],
      "source": [
        "second_response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        ")\n",
        "\n",
        "print(second_response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
