# prompt

LLM に実行して欲しい Task を命令として記述して、User Input data とは独立させます。そして、Input data はわかりやすように「"""」,「###」といった記号で区切ることも多いです。

## Chapter 02

- receipt

```txt
以下の料理のレシピを考えてください。

料理名: """
{dish}
"""
```

- 文脈(Context)を与える

前提条件や外部情報などをムン脈(context) として当てると、文脈に従った回答を得ることができます。

```text
前提条件を踏まえて、以下の料理のレシピを考えてください。

前提条件:"""
分量: 一人分
味の好み: 乾口
"""

料理名: """
カレー
"""
```

- 出力形式を指定する

````text
前提条件を踏まえて、以下の料理のレシピを考えてください。
出力は以下のような JSON 形式にしてください。

```json
{
  "材料": ["材料1", "材料2"],
  "手順": ["手順1", "手順2"]
}
```

前提条件:"""
分量: 一人分
味の好み: 乾口
"""

料理名: """
カレー
"""
```

````

### zero-shot prompting

- テキストをポジティブ・ネガティブ・中立のどれかに分類してください。

```txt
以下のテキストをポジティブ・ネガティブ・中立のどれかに分類してください。

テキスト：ChatGPTはプログラミングの悩みごとをたくさん解決してくれる

分類：
```

### few-shot prompting

prompt でいくつか demonstration を与えることで、求める回答を得やすくなります。そのような手法を few-show prompting と言います。

- zero-shot prompting

```txt
色を回答してください。

Q: バナナ
A:
```

- few-shot prompting

```txt
色を回答してください。

Q: りんご
A: 赤
Q: メロン
A: 緑
Q: バナナ
A:
```

- Zero-shot Chain of Thought(zero-shot Cot) prompting

「step by step で考えてみましょう」入れたことと入れてないことと答えることを見ると step by step の方が段階的に説明があり、多くの Task に効果的である。
なお、Zero-shot Cot prompting と呼ぶのは、先に考案された「Chain of Thought（CoT）プロンプティング」では、few-shot プロンプティングを使い、ステップバイステップで考える例をいくつか含めていたためです。

```txt
私は市場に行って10個のリンゴを買いました。隣人に2つ、修理工に2つ渡しました。それから5つのリンゴを買って1つ食べました。
残りは何個ですか？
回答だけ答えてください。
```

```txt
私は市場に行って10個のリンゴを買いました。隣人に2つ、修理工に2つ渡しました。それから5つのリンゴを買って1つ食べました。残りは何個ですか？
ステップバイステップで考えてみましょう。
```

## Chapter 03
