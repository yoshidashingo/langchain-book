{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUj2y-stek1W"
      },
      "source": [
        "# 5. LangChain解説"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4oSu5DqWgpG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 本書で動作確認済みのchromadb v0.4.10が動作するよう、pydanticを動作確認済みのv1.10.13に固定します。\n",
        "# この処理はpydanticが最初に使われる前に実行する必要があるため、ノートブックの先頭のあたりで実行してください。\n",
        "# もしもうまく動作しない場合、Google Colabのランタイムを再起動または削除して先頭から実行し直してください。\n",
        "#\n",
        "# 関連: https://github.com/yoshidashingo/langchain-book/issues/16\n",
        "!pip install pydantic==1.10.13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqgjYwQUemjV"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.0.292 openai==0.28.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrVLB3DPwF8b"
      },
      "source": [
        "## 5-1 Data connection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg6AiTnKwJik"
      },
      "source": [
        "### Document loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMbWltTYymkJ"
      },
      "outputs": [],
      "source": [
        "!pip install GitPython==3.1.36"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uO4jzLUIwK2c"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import GitLoader\n",
        "\n",
        "def file_filter(file_path):\n",
        "    return file_path.endswith(\".mdx\")\n",
        "\n",
        "loader = GitLoader(\n",
        "    clone_url=\"https://github.com/langchain-ai/langchain\",\n",
        "    repo_path=\"./langchain\",\n",
        "    branch=\"master\",\n",
        "    file_filter=file_filter,\n",
        ")\n",
        "\n",
        "raw_docs = loader.load()\n",
        "print(len(raw_docs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENepdYezyx2K"
      },
      "source": [
        "### Document transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0LDtMDZ56al"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "\n",
        "docs = text_splitter.split_documents(raw_docs)\n",
        "print(len(docs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppuF2moQrLYS"
      },
      "source": [
        "## Text embedding models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRuScpdhCTSo"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install tiktoken==0.5.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDSJOjCLrK_R"
      },
      "outputs": [],
      "source": [
        "query = \"AWSのS3からデータを読み込むためのDocumentLoaderはありますか？\"\n",
        "\n",
        "vector = embeddings.embed_query(query)\n",
        "print(len(vector))\n",
        "print(vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b23RYe2rQMv"
      },
      "source": [
        "### Vector stores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWvhGR9BywjU"
      },
      "outputs": [],
      "source": [
        "!pip install chromadb==0.4.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgYsSMKnyYRH"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "db = Chroma.from_documents(docs, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8Uag8bzuDIe"
      },
      "source": [
        "### Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rh66m1_luPf0"
      },
      "outputs": [],
      "source": [
        "retriever = db.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QB5bVMsyUWC"
      },
      "outputs": [],
      "source": [
        "query = \"AWSのS3からデータを読み込むためのDocumentLoaderはありますか？\"\n",
        "\n",
        "context_docs = retriever.get_relevant_documents(query)\n",
        "print(f\"len = {len(context_docs)}\")\n",
        "\n",
        "first_doc = context_docs[0]\n",
        "print(f\"metadata = {first_doc.metadata}\")\n",
        "print(first_doc.page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RetrievalQA（Chain）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2GNMIC80s2w"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=chat, chain_type=\"stuff\", retriever=retriever)\n",
        "\n",
        "result = qa_chain.run(query)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4Fz0OFVZmSq"
      },
      "source": [
        "## 5-2 Agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HSybywiZn6c"
      },
      "source": [
        "### Agentsの使用例"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import langchain\n",
        "\n",
        "langchain.verbose = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlRHx6ejZBbs"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "tools = load_tools([\"terminal\"])\n",
        "agent_chain = initialize_agent(\n",
        "    tools, chat, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
        ")\n",
        "\n",
        "result = agent_chain.run(\"sample_dataディレクトリにあるファイルの一覧を教えて\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U2AKd4BsSEt"
      },
      "source": [
        "### Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvJUF7XogVRI"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import Tool\n",
        "\n",
        "def my_super_func(param):\n",
        "    return \"42\"\n",
        "\n",
        "tools = [\n",
        "    Tool.from_function(\n",
        "        func=my_super_func,\n",
        "        name=\"The_Answer\",\n",
        "        description=\"生命、宇宙、そして万物についての究極の疑問の答え\"\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoEjpv2XtemN"
      },
      "outputs": [],
      "source": [
        "agent_chain = initialize_agent(\n",
        "    tools, chat, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
        ")\n",
        "\n",
        "result = agent_chain.run(\"この世界の真理を教えてください\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFW6L4Dbtkpv"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain import LLMChain\n",
        "\n",
        "summarize_template = \"\"\"以下の文章を結論だけ一言に要約してください。\n",
        "\n",
        "{input}\n",
        "\"\"\"\n",
        "summarize_prompt = PromptTemplate(\n",
        "   input_variables=[\"input\"],\n",
        "   template=summarize_template,\n",
        ")\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "summarize_chain = LLMChain(llm=chat, prompt=summarize_prompt)\n",
        "\n",
        "tools = [\n",
        "    Tool.from_function(\n",
        "        func=summarize_chain.run,\n",
        "        name=\"Summarizer\",\n",
        "        description=\"Text summarizer\"\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAjRYZTLv7nC"
      },
      "outputs": [],
      "source": [
        "agent_chain = initialize_agent(\n",
        "    tools, chat, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
        ")\n",
        "\n",
        "text = \"\"\"以下を要約してください。\n",
        "\n",
        "こんにちは！私はChatGPTと呼ばれるAI言語モデルです。OpenAIが開発したGPT-3.5アーキテクチャに基づいています。私は自然言語理解と生成に特化しており、さまざまなトピックに関する質問に答えたり、おしゃべりしたりすることが得意です。\n",
        "私のトレーニングデータは2021年9月までの情報に基づいているため、それ以降の出来事については知識がありません。ですが、できる限りお手伝いすることに努めます。\n",
        "質問や会話、情報の共有など、どんなお手伝いでもお気軽にお申し付けください！よろしくお願いします。\"\"\"\n",
        "\n",
        "result = agent_chain.run(text)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_bTNTRGNZNM"
      },
      "source": [
        "### Function callingを使うOpenAI Functions Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XP8Nm_1d6zZV"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "tools = load_tools([\"terminal\"])\n",
        "agent_chain = initialize_agent(tools, chat, agent=AgentType.OPENAI_FUNCTIONS)\n",
        "\n",
        "result = agent_chain.run(\"sample_dataディレクトリにあるファイルの一覧を教えて\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV6Mx0TUO_hT"
      },
      "source": [
        "### 複数のツールを一度に使うOpenAI Multi Functions Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJTSM5gIPDOl"
      },
      "outputs": [],
      "source": [
        "!pip install duckduckgo-search==4.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJAM26YzQQOa"
      },
      "outputs": [],
      "source": [
        "import langchain\n",
        "\n",
        "langchain.debug = True\n",
        "langchain.verbose = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgUyIpfrNq1K"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "tools = load_tools([\"ddg-search\"])\n",
        "agent_chain = initialize_agent(tools, chat, agent=AgentType.OPENAI_MULTI_FUNCTIONS)\n",
        "\n",
        "result = agent_chain.run(\"東京と大阪の天気を教えて\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUk1I4cuY_ef"
      },
      "source": [
        "### （コラム）Function callingを応用したOurputParser・Extraction・Tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0rOddweWbQ2"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import create_extraction_chain\n",
        "\n",
        "schema = {\n",
        "    \"properties\": {\n",
        "        \"person_name\": {\"type\": \"string\"},\n",
        "        \"person_height\": {\"type\": \"integer\"},\n",
        "        \"person_hair_color\": {\"type\": \"string\"},\n",
        "        \"dog_name\": {\"type\": \"string\"},\n",
        "        \"dog_breed\": {\"type\": \"string\"},\n",
        "    },\n",
        "    \"required\": [\"person_name\", \"person_height\"],\n",
        "}\n",
        "text = \"\"\"\n",
        "Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\n",
        "Alex's dog Frosty is a labrador and likes to play hide and seek.\n",
        "\"\"\"\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "chain = create_extraction_chain(schema, chat)\n",
        "\n",
        "people = chain.run(text)\n",
        "print(json.dumps(people, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoyUU671fJ-N"
      },
      "source": [
        "## まとめ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcGAKOdafMy0"
      },
      "source": [
        "### （コラム）Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZedGP8fZPtk"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.evaluation import load_evaluator\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
        "\n",
        "evaluator = load_evaluator(\"qa\", eval_llm=chat)\n",
        "\n",
        "result = evaluator.evaluate_strings(\n",
        "    input=\"私は市場に行って10個のリンゴを買いました。隣人に2つ、修理工に2つ渡しました。それから5つのリンゴを買って1つ食べました。残りは何個ですか？\",\n",
        "    prediction=\"\"\"1最初に10個のリンゴを買い、その中から隣人と修理工にそれぞれ2個ずつ渡しました。そのため、まず手元に残ったリンゴは10 - 2 - 2 = 6個となります。\n",
        "\n",
        "その後、さらに5個のリンゴを買い、1つ食べました。これにより手元のリンゴは6 + 5 - 1 = 10個となります。\"\"\",\n",
        "    reference=\"10個\",\n",
        ")\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "上記の入力は [Chain-of-Thoughtプロンプティング | Prompt Engineering Guide](https://www.promptingguide.ai/jp/techniques/cot) から引用しました。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
