{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUj2y-stek1W"
      },
      "source": [
        "# 5. LangChain解説"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4oSu5DqWgpG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqgjYwQUemjV"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-core==0.1.18 langchain==0.1.5 langchain-openai==0.0.5 langchain_community==0.0.17"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrVLB3DPwF8b"
      },
      "source": [
        "## 5-1 Data connection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg6AiTnKwJik"
      },
      "source": [
        "### Document loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMbWltTYymkJ"
      },
      "outputs": [],
      "source": [
        "!pip install GitPython==3.1.41"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uO4jzLUIwK2c"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import GitLoader\n",
        "\n",
        "def file_filter(file_path):\n",
        "    return file_path.endswith(\".mdx\")\n",
        "\n",
        "loader = GitLoader(\n",
        "    clone_url=\"https://github.com/langchain-ai/langchain\",\n",
        "    repo_path=\"./langchain\",\n",
        "    branch=\"master\",\n",
        "    file_filter=file_filter,\n",
        ")\n",
        "\n",
        "raw_docs = loader.load()\n",
        "print(len(raw_docs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENepdYezyx2K"
      },
      "source": [
        "### Document transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0LDtMDZ56al"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "\n",
        "docs = text_splitter.split_documents(raw_docs)\n",
        "print(len(docs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppuF2moQrLYS"
      },
      "source": [
        "## Text embedding models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRuScpdhCTSo"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Jy_oJoVJI20"
      },
      "outputs": [],
      "source": [
        "!pip install tiktoken==0.5.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDSJOjCLrK_R"
      },
      "outputs": [],
      "source": [
        "query = \"AWSのS3からデータを読み込むためのDocumentLoaderはありますか？\"\n",
        "\n",
        "vector = embeddings.embed_query(query)\n",
        "print(len(vector))\n",
        "print(vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b23RYe2rQMv"
      },
      "source": [
        "### Vector stores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWvhGR9BywjU"
      },
      "outputs": [],
      "source": [
        "!pip install chromadb==0.4.22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgYsSMKnyYRH"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "db = Chroma.from_documents(docs, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8Uag8bzuDIe"
      },
      "source": [
        "### Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rh66m1_luPf0"
      },
      "outputs": [],
      "source": [
        "retriever = db.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QB5bVMsyUWC"
      },
      "outputs": [],
      "source": [
        "query = \"AWSのS3からデータを読み込むためのDocumentLoaderはありますか？\"\n",
        "\n",
        "context_docs = retriever.get_relevant_documents(query)\n",
        "print(f\"len = {len(context_docs)}\")\n",
        "\n",
        "first_doc = context_docs[0]\n",
        "print(f\"metadata = {first_doc.metadata}\")\n",
        "print(first_doc.page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w4HmITBJI21"
      },
      "source": [
        "### RetrievalQA（Chain）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2GNMIC80s2w"
      },
      "outputs": [],
      "source": [
        "# LCELでのRAGの実装例は以下のようになります。\n",
        "#\n",
        "# 参考: https://python.langchain.com/docs/expression_language/cookbook/retrieval\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"以下の文脈だけを踏まえて質問に回答してください。\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "result = chain.invoke(query)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4Fz0OFVZmSq"
      },
      "source": [
        "## 5-2 Agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HSybywiZn6c"
      },
      "source": [
        "### Agentsの使用例"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EW2_UI6mJI22"
      },
      "outputs": [],
      "source": [
        "from langchain_core.globals import set_verbose\n",
        "\n",
        "set_verbose(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLzsA82BPTPj"
      },
      "outputs": [],
      "source": [
        "# terminalというツールを使うため、langchain-experimentalをインストール\n",
        "# ReActによるAgentのプロンプトをダウンロードするため、langchainhubをインストール\n",
        "!pip install langchain-experimental==0.0.50 langchainhub==0.1.14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlRHx6ejZBbs"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_react_agent, load_tools\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "tools = load_tools([\"terminal\"])\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "agent = create_react_agent(chat, tools, prompt)\n",
        "\n",
        "agent_chain = AgentExecutor(agent=agent, tools=tools)\n",
        "\n",
        "result = agent_chain.invoke({\"input\": \"sample_dataディレクトリにあるファイルの一覧を教えて\"})\n",
        "print(result[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U2AKd4BsSEt"
      },
      "source": [
        "### Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvJUF7XogVRI"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import Tool\n",
        "\n",
        "def my_super_func(param):\n",
        "    return \"42\"\n",
        "\n",
        "tools = [\n",
        "    Tool.from_function(\n",
        "        func=my_super_func,\n",
        "        name=\"The_Answer\",\n",
        "        description=\"生命、宇宙、そして万物についての究極の疑問の答え\"\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoEjpv2XtemN"
      },
      "outputs": [],
      "source": [
        "agent = create_react_agent(chat, tools, prompt)\n",
        "agent_chain = AgentExecutor(agent=agent, tools=tools)\n",
        "\n",
        "result = agent_chain.invoke({\"input\": \"この世界の真理を教えてください\"})\n",
        "print(result[\"output\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFW6L4Dbtkpv"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "summarize_prompt = PromptTemplate.from_template(\n",
        "    \"\"\"以下の文章を結論だけ一言に要約してください。\n",
        "\n",
        "{input}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "summarize_chain = (\n",
        "    {\"input\": RunnablePassthrough()}\n",
        "    | summarize_prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "tools = [\n",
        "    Tool.from_function(\n",
        "        func=summarize_chain.invoke,\n",
        "        name=\"Summarizer\",\n",
        "        description=\"Text summarizer\"\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAjRYZTLv7nC"
      },
      "outputs": [],
      "source": [
        "agent = create_react_agent(chat, tools, prompt)\n",
        "agent_chain = AgentExecutor(agent=agent, tools=tools)\n",
        "\n",
        "text = \"\"\"以下を要約してください。\n",
        "\n",
        "こんにちは！私はChatGPTと呼ばれるAI言語モデルです。OpenAIが開発したGPT-3.5アーキテクチャに基づいています。私は自然言語理解と生成に特化しており、さまざまなトピックに関する質問に答えたり、おしゃべりしたりすることが得意です。\n",
        "私のトレーニングデータは2021年9月までの情報に基づいているため、それ以降の出来事については知識がありません。ですが、できる限りお手伝いすることに努めます。\n",
        "質問や会話、情報の共有など、どんなお手伝いでもお気軽にお申し付けください！よろしくお願いします。\"\"\"\n",
        "\n",
        "result = agent_chain.invoke({\"input\": text})\n",
        "print(result[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_bTNTRGNZNM"
      },
      "source": [
        "### Function callingを使うOpenAI Functions Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XP8Nm_1d6zZV"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "tools = load_tools([\"terminal\"])\n",
        "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
        "\n",
        "agent = create_openai_tools_agent(chat, tools, prompt)\n",
        "agent_chain = AgentExecutor(agent=agent, tools=tools)\n",
        "\n",
        "result = agent_chain.invoke({\"input\": \"sample_dataディレクトリにあるファイルの一覧を教えて\"})\n",
        "print(result[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV6Mx0TUO_hT"
      },
      "source": [
        "### 複数のツールを一度に使うOpenAI Multi Functions Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJTSM5gIPDOl"
      },
      "outputs": [],
      "source": [
        "!pip install duckduckgo-search==5.3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJAM26YzQQOa"
      },
      "outputs": [],
      "source": [
        "from langchain_core.globals import set_debug, set_verbose\n",
        "\n",
        "set_debug(True)\n",
        "set_verbose(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgUyIpfrNq1K"
      },
      "outputs": [],
      "source": [
        "# Chat Completions APIのアップデートにより、「functions」ではなく「tools」を使用するのが推奨になりました。\n",
        "# 「tools」では一度に複数のツールの呼び出しが可能なため、OpenAI Multi Functions Agentを使う必要はなくなりました。\n",
        "# ただし、「tools」で一度に複数のツールが呼び出すようにするには、gpt-3.5-turbo-1106やgpt-3.5-turbo-0125といった新しいモデルを使う必要があります。\n",
        "\n",
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_openai_tools_agent, load_tools\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
        "tools = load_tools([\"ddg-search\"])\n",
        "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
        "\n",
        "agent = create_openai_tools_agent(chat, tools, prompt)\n",
        "agent_chain = AgentExecutor(agent=agent, tools=tools)\n",
        "\n",
        "result = agent_chain.invoke({\"input\": \"東京と大阪の天気を教えて\"})\n",
        "print(result[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUk1I4cuY_ef"
      },
      "source": [
        "### （コラム）Function callingを応用したOurputParser・Extraction・Tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxS6-i6IUrfS"
      },
      "outputs": [],
      "source": [
        "from langchain_core.globals import set_debug, set_verbose\n",
        "\n",
        "set_debug(False)\n",
        "set_verbose(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0rOddweWbQ2"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import Optional\n",
        "\n",
        "from langchain.output_parsers.openai_tools import JsonOutputToolsParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "class Person(BaseModel):\n",
        "    person_name: str\n",
        "    person_height: str\n",
        "    person_hair_color: Optional[str]\n",
        "    dog_name: Optional[str]\n",
        "    dog_breed: Optional[str]\n",
        "\n",
        "class People(BaseModel):\n",
        "    people: list[Person]\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0).bind_tools([People])\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are helpful assistant\"),\n",
        "    (\"user\", \"{input}\")\n",
        "])\n",
        "\n",
        "chain = prompt | model | JsonOutputToolsParser()\n",
        "\n",
        "text = \"\"\"\n",
        "Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\n",
        "Alex's dog Frosty is a labrador and likes to play hide and seek.\n",
        "\"\"\"\n",
        "\n",
        "people = chain.invoke({\"input\": text})\n",
        "print(json.dumps(people, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoyUU671fJ-N"
      },
      "source": [
        "## まとめ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcGAKOdafMy0"
      },
      "source": [
        "### （コラム）Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZedGP8fZPtk"
      },
      "outputs": [],
      "source": [
        "from langchain.evaluation import load_evaluator\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
        "\n",
        "evaluator = load_evaluator(\"qa\", eval_llm=chat)\n",
        "\n",
        "result = evaluator.evaluate_strings(\n",
        "    input=\"私は市場に行って10個のリンゴを買いました。隣人に2つ、修理工に2つ渡しました。それから5つのリンゴを買って1つ食べました。残りは何個ですか？\",\n",
        "    prediction=\"\"\"1最初に10個のリンゴを買い、その中から隣人と修理工にそれぞれ2個ずつ渡しました。そのため、まず手元に残ったリンゴは10 - 2 - 2 = 6個となります。\n",
        "\n",
        "その後、さらに5個のリンゴを買い、1つ食べました。これにより手元のリンゴは6 + 5 - 1 = 10個となります。\"\"\",\n",
        "    reference=\"10個\",\n",
        ")\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UJqIaNPJI2-"
      },
      "source": [
        "上記の入力は [Chain-of-Thoughtプロンプティング | Prompt Engineering Guide](https://www.promptingguide.ai/jp/techniques/cot) から引用しました。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
